{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch_geometric in c:\\users\\rahul\\anaconda3\\lib\\site-packages (2.6.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from torch_geometric) (3.9.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from torch_geometric) (2024.3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from torch_geometric) (3.1.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from torch_geometric) (1.26.4)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from torch_geometric) (5.9.0)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from torch_geometric) (3.0.9)\n",
      "Requirement already satisfied: requests in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from torch_geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from torch_geometric) (4.67.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from aiohttp->torch_geometric) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from aiohttp->torch_geometric) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from aiohttp->torch_geometric) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from aiohttp->torch_geometric) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from aiohttp->torch_geometric) (1.9.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from jinja2->torch_geometric) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from requests->torch_geometric) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from requests->torch_geometric) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from requests->torch_geometric) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from requests->torch_geometric) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from tqdm->torch_geometric) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Rahul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Rahul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import networkx as nx\n",
    "import warnings\n",
    "%pip install torch_geometric\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing function\n",
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Function to load and preprocess the dataset\n",
    "def load_dataset(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"Loaded dataset with {len(df)} poems\")\n",
    "    \n",
    "    # Cheecking for missing value\n",
    "    if df['poem_text'].isna().sum() > 0:\n",
    "        print(f\"Warning: {df['poem_text'].isna().sum()} poems have NaN text. Removing them.\")\n",
    "        df = df.dropna(subset=['poem_text'])\n",
    "    \n",
    "    # Preprocess text\n",
    "    df['processed_text'] = df['poem_text'].apply(preprocess_text)\n",
    "    \n",
    "    if 'form' in df.columns:\n",
    "        target = 'form'\n",
    "    elif 'theme_tags' in df.columns:\n",
    "        df['primary_theme'] = df['theme_tags'].apply(lambda x: x.split(',')[0].strip() if isinstance(x, str) and ',' in x else x)\n",
    "        target = 'primary_theme'\n",
    "    \n",
    "    # Keep only classes with at least 5 samples\n",
    "    class_counts = df[target].value_counts()\n",
    "    valid_classes = class_counts[class_counts >= 5].index\n",
    "    df = df[df[target].isin(valid_classes)]\n",
    "    \n",
    "    print(f\"After preprocessing: {len(df)} poems and {len(valid_classes)} classes\")\n",
    "    print(f\"Target column: {target}\")\n",
    "    print(f\"Top 5 classes: {class_counts[:5].to_dict()}\")\n",
    "    \n",
    "    # Encoding the  target variable\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    df['target_id'] = le.fit_transform(df[target])\n",
    "    \n",
    "    return df, le, target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split dataset\n",
    "def split_data(df, test_size=0.2, val_size=0.1):\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "        df['processed_text'], df['target_id'], \n",
    "        test_size=test_size, random_state=42, stratify=df['target_id']\n",
    "    )\n",
    "    \n",
    "    # Further split train into train and validation\n",
    "    val_ratio = val_size / (1 - test_size)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val, y_train_val, \n",
    "        test_size=val_ratio, random_state=42, stratify=y_train_val\n",
    "    )\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRADITIONAL MACHINE LEARNING\n",
    "\n",
    "# 1. Naive Bayes\n",
    "def train_naive_bayes(X_train, y_train, X_test, y_test):\n",
    "    # Create TF-IDF features\n",
    "    tfidf = TfidfVectorizer(max_features=5000)\n",
    "    X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "    X_test_tfidf = tfidf.transform(X_test)\n",
    "    \n",
    "    # Train Naive Bayes\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = nb.predict(X_test_tfidf)\n",
    "    \n",
    "    # Evaluate\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Naive Bayes Accuracy: {accuracy:.4f}\")\n",
    "    print(report)\n",
    "    \n",
    "    return nb, tfidf, accuracy, report\n",
    "\n",
    "# 2. Random Forest\n",
    "def train_random_forest(X_train, y_train, X_test, y_test):\n",
    "    # Create TF-IDF features\n",
    "    tfidf = TfidfVectorizer(max_features=3000)\n",
    "    X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "    X_test_tfidf = tfidf.transform(X_test)\n",
    "    \n",
    "    # Train Random Forest\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = rf.predict(X_test_tfidf)\n",
    "    \n",
    "    # Evaluate\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Random Forest Accuracy: {accuracy:.4f}\")\n",
    "    print(report)\n",
    "    \n",
    "    return rf, tfidf, accuracy, report\n",
    "\n",
    "# 3. XGBoost\n",
    "def train_xgboost(X_train, y_train, X_test, y_test):\n",
    "    # Create TF-IDF features\n",
    "    tfidf = TfidfVectorizer(max_features=3000)\n",
    "    X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "    X_test_tfidf = tfidf.transform(X_test)\n",
    "    \n",
    "    # Train XGBoost\n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        objective='multi:softmax',\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    )\n",
    "    xgb_model.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = xgb_model.predict(X_test_tfidf)\n",
    "    \n",
    "    # Evaluate\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(f\"XGBoost Accuracy: {accuracy:.4f}\")\n",
    "    print(report)\n",
    "    \n",
    "    return xgb_model, tfidf, accuracy, report\n",
    "\n",
    "# 4. SVM\n",
    "def train_svm(X_train, y_train, X_test, y_test):\n",
    "    # Create TF-IDF features\n",
    "    tfidf = TfidfVectorizer(max_features=3000)\n",
    "    X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "    X_test_tfidf = tfidf.transform(X_test)\n",
    "    \n",
    "    # Train SVM\n",
    "    svm = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "    svm.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = svm.predict(X_test_tfidf)\n",
    "    \n",
    "    # Evaluate\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(f\"SVM Accuracy: {accuracy:.4f}\")\n",
    "    print(report)\n",
    "    \n",
    "    return svm, tfidf, accuracy, report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEEP LEARNING - LSTM\n",
    "\n",
    "class PoemDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer=None, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def build_vocab(self):\n",
    "        word_set = set()\n",
    "        for text in self.texts:\n",
    "            words = text.split()\n",
    "            word_set.update(words)\n",
    "        \n",
    "        for word in word_set:\n",
    "            if word not in self.word_to_idx:\n",
    "                self.word_to_idx[word] = len(self.word_to_idx)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts.iloc[idx]\n",
    "        label = self.labels.iloc[idx]\n",
    "        \n",
    "        if self.tokenizer:\n",
    "            encoding = self.tokenizer(\n",
    "                text,\n",
    "                add_special_tokens=True,\n",
    "                max_length=self.max_len,\n",
    "                return_token_type_ids=False,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_tensors='pt',\n",
    "            )\n",
    "            \n",
    "            return {\n",
    "                'input_ids': encoding['input_ids'].flatten(),\n",
    "                'attention_mask': encoding['attention_mask'].flatten(),\n",
    "                'label': torch.tensor(label, dtype=torch.long)\n",
    "            }\n",
    "        else:\n",
    "            # For LSTM\n",
    "            words = text.split()\n",
    "            if len(words) > self.max_len:\n",
    "                words = words[:self.max_len]\n",
    "            if len(words) < self.max_len:\n",
    "                words = words + ['<PAD>'] * (self.max_len - len(words))\n",
    "            \n",
    "            indices = [self.word_to_idx.get(word, self.word_to_idx['<UNK>']) for word in words]\n",
    "            return torch.tensor(indices), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers=2, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           bidirectional=True, \n",
    "                           dropout=dropout, \n",
    "                           batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        \n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "        \n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
    "        \n",
    "        return self.fc(self.dropout(hidden))\n",
    "\n",
    "def train_lstm_model(X_train, y_train, X_val, y_val, X_test, y_test, n_classes):\n",
    "    # Create datasets\n",
    "    train_dataset = PoemDataset(X_train, y_train)\n",
    "    val_dataset = PoemDataset(X_val, y_val, tokenizer=None, max_len=128)\n",
    "    test_dataset = PoemDataset(X_test, y_test, tokenizer=None, max_len=128)\n",
    "    \n",
    "    # Update vocabulary for validation and test sets\n",
    "    val_dataset.word_to_idx = train_dataset.word_to_idx\n",
    "    test_dataset.word_to_idx = train_dataset.word_to_idx\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "    \n",
    "    # Initialize model\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    vocab_size = len(train_dataset.word_to_idx)\n",
    "    embedding_dim = 100\n",
    "    hidden_dim = 256\n",
    "    output_dim = n_classes\n",
    "    n_layers = 2\n",
    "    dropout = 0.5\n",
    "    \n",
    "    model = LSTMClassifier(vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Define optimizer and loss function\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Training loop\n",
    "    epochs = 10\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        \n",
    "        for text, labels in train_loader:\n",
    "            text, labels = text.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(text)\n",
    "            \n",
    "            loss = criterion(predictions, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            predicted_classes = predictions.argmax(dim=1)\n",
    "            train_acc += (predicted_classes == labels).sum().item()\n",
    "        \n",
    "        # Calculate training metrics\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        train_acc = train_acc / len(train_dataset)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_acc = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for text, labels in val_loader:\n",
    "                text, labels = text.to(device), labels.to(device)\n",
    "                predictions = model(text)\n",
    "                \n",
    "                loss = criterion(predictions, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                predicted_classes = predictions.argmax(dim=1)\n",
    "                val_acc += (predicted_classes == labels).sum().item()\n",
    "        \n",
    "        # Calculate validation metrics\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_acc = val_acc / len(val_dataset)\n",
    "        \n",
    "        print(f'Epoch: {epoch+1}')\n",
    "        print(f'\\tTrain Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "        print(f'\\tVal Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'lstm_model.pt')\n",
    "    \n",
    "    # Test\n",
    "    model.load_state_dict(torch.load('lstm_model.pt'))\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for text, labels in test_loader:\n",
    "            text, labels = text.to(device), labels.to(device)\n",
    "            predictions = model(text)\n",
    "            \n",
    "            loss = criterion(predictions, labels)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            predicted_classes = predictions.argmax(dim=1)\n",
    "            test_acc += (predicted_classes == labels).sum().item()\n",
    "            \n",
    "            y_pred.extend(predicted_classes.cpu().numpy())\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate test metrics\n",
    "    test_loss = test_loss / len(test_loader)\n",
    "    test_acc = test_acc / len(test_dataset)\n",
    "    \n",
    "    print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    print(report)\n",
    "    \n",
    "    return model, test_acc, report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOVEL APPROACHES\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# 1. GNN (Graph Neural Network)\n",
    "def text_to_graph(text, window_size=3):\n",
    "    \"\"\"Convert text to a graph where nodes are words and edges connect words within a sliding window\"\"\"\n",
    "    words = text.split()\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add nodes\n",
    "    for i, word in enumerate(words):\n",
    "        G.add_node(i, word=word)\n",
    "    \n",
    "    # Add edges for words within window_size\n",
    "    for i in range(len(words)):\n",
    "        for j in range(i+1, min(i+window_size+1, len(words))):\n",
    "            G.add_edge(i, j)\n",
    "    \n",
    "    return G\n",
    "\n",
    "def graph_to_pyg_data(G, word_to_idx, label):\n",
    "    \"\"\"Convert networkx graph to PyTorch Geometric Data\"\"\"\n",
    "    # Node features (word embeddings)\n",
    "    x = []\n",
    "    for node in sorted(G.nodes()):\n",
    "        word = G.nodes[node]['word']\n",
    "        idx = word_to_idx.get(word, word_to_idx['<UNK>'])\n",
    "        x.append([idx])  # We'll use indices and let the model learn embeddings\n",
    "    \n",
    "    # Edge indices\n",
    "    edge_index = []\n",
    "    for edge in G.edges():\n",
    "        edge_index.append([edge[0], edge[1]])\n",
    "        edge_index.append([edge[1], edge[0]])  # Add reverse edge for undirected graph\n",
    "    \n",
    "    # Convert to tensors\n",
    "    x = torch.tensor(x, dtype=torch.long)\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t()\n",
    "    y = torch.tensor(label, dtype=torch.long)\n",
    "    \n",
    "    return Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "class GNNClassifier(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(GNNClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.conv1 = GCNConv(embedding_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.embedding(x.squeeze())\n",
    "        x = torch.relu(self.conv1(x, edge_index))\n",
    "        x = torch.relu(self.conv2(x, edge_index))\n",
    "        x = global_mean_pool(x, data.batch)  # Ensure global pooling is correctly applied\n",
    "        x = self.dropout(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "def prepare_graph_datasets(X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    # Create word to index mapping\n",
    "    word_set = set()\n",
    "    for text in X_train:\n",
    "        words = text.split()\n",
    "        word_set.update(words)\n",
    "    \n",
    "    word_to_idx = {'<PAD>': 0, '<UNK>': 1}\n",
    "    for word in word_set:\n",
    "        if word not in word_to_idx:\n",
    "            word_to_idx[word] = len(word_to_idx)\n",
    "    \n",
    "    # Convert texts to graphs\n",
    "    print(\"Converting texts to graphs...\")\n",
    "    train_graphs = [text_to_graph(text) for text in X_train]\n",
    "    val_graphs = [text_to_graph(text) for text in X_val]\n",
    "    test_graphs = [text_to_graph(text) for text in X_test]\n",
    "    \n",
    "    # Convert to PyG Data objects\n",
    "    train_data = [graph_to_pyg_data(g, word_to_idx, label) for g, label in zip(train_graphs, y_train)]\n",
    "    val_data = [graph_to_pyg_data(g, word_to_idx, label) for g, label in zip(val_graphs, y_val)]\n",
    "    test_data = [graph_to_pyg_data(g, word_to_idx, label) for g, label in zip(test_graphs, y_test)]\n",
    "    \n",
    "    return train_data, val_data, test_data, word_to_idx\n",
    "\n",
    "def train_gnn_model(X_train, y_train, X_val, y_val, X_test, y_test, n_classes):\n",
    "    # Prepare graph datasets\n",
    "    train_data, val_data, test_data, word_to_idx = prepare_graph_datasets(X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "    \n",
    "    train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=32)\n",
    "    test_loader = DataLoader(test_data, batch_size=32)\n",
    "\n",
    "    # Initialize model\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    vocab_size = len(word_to_idx)\n",
    "    embedding_dim = 100\n",
    "    hidden_dim = 256\n",
    "    output_dim = n_classes\n",
    "    \n",
    "    model = GNNClassifier(vocab_size, embedding_dim, hidden_dim, output_dim)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Define optimizer and loss function\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Training loop\n",
    "    epochs = 10\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(batch)\n",
    "            \n",
    "            loss = criterion(predictions, batch.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            predicted_classes = predictions.argmax(dim=1)\n",
    "            train_acc += (predicted_classes == batch.y).sum().item()\n",
    "        \n",
    "        # Calculate training metrics\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        train_acc = train_acc / len(train_data)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_acc = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                batch = batch.to(device)\n",
    "                predictions = model(batch)\n",
    "                \n",
    "                loss = criterion(predictions, batch.y)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                predicted_classes = predictions.argmax(dim=1)\n",
    "                val_acc += (predicted_classes == batch.y).sum().item()\n",
    "        \n",
    "        # Calculate validation metrics\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_acc = val_acc / len(val_data)\n",
    "        \n",
    "        print(f'Epoch: {epoch+1}')\n",
    "        print(f'\\tTrain Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "        print(f'\\tVal Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'gnn_model.pt')\n",
    "    \n",
    "    # Test\n",
    "    model.load_state_dict(torch.load('gnn_model.pt'))\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            batch = batch.to(device)\n",
    "            predictions = model(batch)\n",
    "            \n",
    "            loss = criterion(predictions, batch.y)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            predicted_classes = predictions.argmax(dim=1)\n",
    "            test_acc += (predicted_classes == batch.y).sum().item()\n",
    "            \n",
    "            y_pred.extend(predicted_classes.cpu().numpy())\n",
    "            y_true.extend(batch.y.cpu().numpy())\n",
    "    \n",
    "    # Calculate test metrics\n",
    "    test_loss = test_loss / len(test_loader)\n",
    "    test_acc = test_acc / len(test_data)\n",
    "    \n",
    "    print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    print(report)\n",
    "    \n",
    "    return model, test_acc, report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. BERT + LSTM\n",
    "class BertLSTMClassifier(nn.Module):\n",
    "    def __init__(self, bert_model_name, hidden_dim, output_dim, n_layers=2, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        self.lstm = nn.LSTM(self.bert.config.hidden_size,\n",
    "                           hidden_dim,\n",
    "                           num_layers=n_layers,\n",
    "                           bidirectional=True,\n",
    "                           dropout=dropout,\n",
    "                           batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Get BERT outputs\n",
    "        bert_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = bert_outputs.last_hidden_state\n",
    "        \n",
    "        # Pass through LSTM\n",
    "        lstm_output, (hidden, cell) = self.lstm(sequence_output)\n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
    "        \n",
    "        return self.fc(self.dropout(hidden))\n",
    "\n",
    "def train_bert_lstm_model(X_train, y_train, X_val, y_val, X_test, y_test, n_classes):\n",
    "    # Initialize BERT tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = PoemDataset(X_train, y_train, tokenizer=tokenizer, max_len=128)\n",
    "    val_dataset = PoemDataset(X_val, y_val, tokenizer=tokenizer, max_len=128)\n",
    "    test_dataset = PoemDataset(X_test, y_test, tokenizer=tokenizer, max_len=128)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "    \n",
    "    # Initialize model\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    hidden_dim = 256\n",
    "    output_dim = n_classes\n",
    "    n_layers = 2\n",
    "    dropout = 0.5\n",
    "    \n",
    "    model = BertLSTMClassifier('bert-base-uncased', hidden_dim, output_dim, n_layers, dropout)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Define optimizer and loss function\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Training loop\n",
    "    epochs = 3  # Fewer epochs due to computational cost\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(input_ids, attention_mask)\n",
    "            \n",
    "            loss = criterion(predictions, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            predicted_classes = predictions.argmax(dim=1)\n",
    "            train_acc += (predicted_classes == labels).sum().item()\n",
    "        \n",
    "        # Calculate training metrics\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        train_acc = train_acc / len(train_dataset)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_acc = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "                \n",
    "                predictions = model(input_ids, attention_mask)\n",
    "                \n",
    "                loss = criterion(predictions, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                predicted_classes = predictions.argmax(dim=1)\n",
    "                val_acc += (predicted_classes == labels).sum().item()\n",
    "        \n",
    "        # Calculate validation metrics\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_acc = val_acc / len(val_dataset)\n",
    "        \n",
    "        print(f'Epoch: {epoch+1}')\n",
    "        print(f'\\tTrain Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "        print(f'\\tVal Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'bert_lstm_model.pt')\n",
    "    \n",
    "    # Test\n",
    "   # Test\n",
    "    model.load_state_dict(torch.load('bert_lstm_model.pt'))\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            predictions = model(input_ids, attention_mask)\n",
    "            \n",
    "            loss = criterion(predictions, labels)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            predicted_classes = predictions.argmax(dim=1)\n",
    "            test_acc += (predicted_classes == labels).sum().item()\n",
    "            \n",
    "            y_pred.extend(predicted_classes.cpu().numpy())\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate test metrics\n",
    "    test_loss = test_loss / len(test_loader)\n",
    "    test_acc = test_acc / len(test_dataset)\n",
    "    \n",
    "    print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    print(report)\n",
    "    \n",
    "    return model, test_acc, report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "def visualize_results(results):\n",
    "    models = list(results.keys())\n",
    "    accuracies = [results[model]['accuracy'] for model in models]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(models, accuracies, color='steelblue')\n",
    "    plt.xlabel('Models')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Model Comparison')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Add accuracy values on top of bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                 f'{height:.4f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Confusion matrix visualization\n",
    "def plot_confusion_matrix(y_true, y_pred, labels):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Feature importance for tree-based models\n",
    "def plot_feature_importance(model, vectorizer, top_n=20):\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        # Get feature importances\n",
    "        importances = model.feature_importances_\n",
    "        # Get feature names\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "        \n",
    "        # Create DataFrame for visualization\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': importances\n",
    "        })\n",
    "        \n",
    "        # Sort by importance\n",
    "        feature_importance = feature_importance.sort_values('importance', ascending=False).head(top_n)\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.barplot(x='importance', y='feature', data=feature_importance)\n",
    "        plt.title(f'Top {top_n} Important Features')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"This model doesn't have feature_importances_ attribute.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Main function to run the code\n",
    "def main():\n",
    "    # Load and preprocess data\n",
    "    df, label_encoder, target = load_dataset(r'C:\\Users\\Rahul\\Desktop\\Web_App\\NLP1\\poetry-evaluation_public-domain-poems.csv')\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = split_data(df)\n",
    "    \n",
    "    # Number of classes\n",
    "    n_classes = len(label_encoder.classes_)\n",
    "    print(f\"Number of classes: {n_classes}\")\n",
    "    \n",
    "    # Train and evaluate models\n",
    "    results = {}\n",
    "    \n",
    "    print(\"\\n Training Naive Bayes \")\n",
    "    nb_model, nb_vectorizer, nb_acc, nb_report = train_naive_bayes(X_train, y_train, X_test, y_test)\n",
    "    results['Naive Bayes'] = {'accuracy': nb_acc, 'report': nb_report}\n",
    "    \n",
    "    print(\"\\n Training Random Forest\")\n",
    "    rf_model, rf_vectorizer, rf_acc, rf_report = train_random_forest(X_train, y_train, X_test, y_test)\n",
    "    results['Random Forest'] = {'accuracy': rf_acc, 'report': rf_report}\n",
    "    \n",
    "    print(\"\\n Training XGBoost \")\n",
    "    xgb_model, xgb_vectorizer, xgb_acc, xgb_report = train_xgboost(X_train, y_train, X_test, y_test)\n",
    "    results['XGBoost'] = {'accuracy': xgb_acc, 'report': xgb_report}\n",
    "    \n",
    "    print(\"\\n Training SVM \")\n",
    "    svm_model, svm_vectorizer, svm_acc, svm_report = train_svm(X_train, y_train, X_test, y_test)\n",
    "    results['SVM'] = {'accuracy': svm_acc, 'report': svm_report}\n",
    "    \n",
    "    print(\"\\n Training LSTM \")\n",
    "    lstm_model, lstm_acc, lstm_report = train_lstm_model(X_train, y_train, X_val, y_val, X_test, y_test, n_classes)\n",
    "    results['LSTM'] = {'accuracy': lstm_acc, 'report': lstm_report}\n",
    "    \n",
    "    print(\"\\n Training GNN \")\n",
    "    gnn_model, gnn_acc, gnn_report = train_gnn_model(X_train, y_train, X_val, y_val, X_test, y_test, n_classes)\n",
    "    results['GNN'] = {'accuracy': gnn_acc, 'report': gnn_report}\n",
    "    \n",
    "    print(\"\\n Training BERT+LSTM \")\n",
    "    bert_lstm_model, bert_lstm_acc, bert_lstm_report = train_bert_lstm_model(X_train, y_train, X_val, y_val, X_test, y_test, n_classes)\n",
    "    results['BERT+LSTM'] = {'accuracy': bert_lstm_acc, 'report': bert_lstm_report}\n",
    "    \n",
    "    # Visualize results\n",
    "    visualize_results(results)\n",
    "    \n",
    "    # Get best model\n",
    "    best_model = max(results, key=lambda x: results[x]['accuracy'])\n",
    "    print(f\"\\nBest model: {best_model} with accuracy: {results[best_model]['accuracy']:.4f}\")\n",
    "    \n",
    "    # For tree-based models, plot feature importance\n",
    "    if best_model in ['Random Forest', 'XGBoost']:\n",
    "        model = rf_model if best_model == 'Random Forest' else xgb_model\n",
    "        vectorizer = rf_vectorizer if best_model == 'Random Forest' else xgb_vectorizer\n",
    "        plot_feature_importance(model, vectorizer)\n",
    "    \n",
    "    # Save best model\n",
    "    if best_model == 'Naive Bayes':\n",
    "        import joblib\n",
    "        joblib.dump((nb_model, nb_vectorizer, label_encoder), 'best_model.pkl')\n",
    "    elif best_model == 'Random Forest':\n",
    "        import joblib\n",
    "        joblib.dump((rf_model, rf_vectorizer, label_encoder), 'best_model.pkl')\n",
    "    elif best_model == 'XGBoost':\n",
    "        import joblib\n",
    "        joblib.dump((xgb_model, xgb_vectorizer, label_encoder), 'best_model.pkl')\n",
    "    elif best_model == 'SVM':\n",
    "        import joblib\n",
    "        joblib.dump((svm_model, svm_vectorizer, label_encoder), 'best_model.pkl')\n",
    "    # For deep learning models, they are already saved during training\n",
    "    \n",
    "    print(\"Best model saved!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 1453 poems\n",
      "After preprocessing: 1443 poems and 17 classes\n",
      "Target column: form\n",
      "Top 5 classes: {'sonnet': 585, 'couplet': 302, 'blank verse': 73, 'common measure': 69, 'elegy': 67}\n",
      "Number of classes: 17\n",
      "\n",
      "==== Training Naive Bayes ====\n",
      "Naive Bayes Accuracy: 0.4256\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.00      0.00      0.00        13\n",
      "           2       0.00      0.00      0.00        15\n",
      "           3       0.00      0.00      0.00        14\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.86      0.10      0.18        61\n",
      "           6       0.00      0.00      0.00         9\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00        13\n",
      "           9       0.00      0.00      0.00        11\n",
      "          10       0.00      0.00      0.00         3\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00         9\n",
      "          13       0.00      0.00      0.00         7\n",
      "          14       0.00      0.00      0.00         8\n",
      "          15       0.00      0.00      0.00         3\n",
      "          16       0.41      1.00      0.59       117\n",
      "\n",
      "    accuracy                           0.43       289\n",
      "   macro avg       0.07      0.06      0.04       289\n",
      "weighted avg       0.35      0.43      0.27       289\n",
      "\n",
      "\n",
      "==== Training Random Forest ====\n",
      "Random Forest Accuracy: 0.5087\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.00      0.00      0.00        13\n",
      "           2       0.75      0.20      0.32        15\n",
      "           3       0.00      0.00      0.00        14\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.39      0.43      0.41        61\n",
      "           6       0.00      0.00      0.00         9\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00        13\n",
      "           9       0.00      0.00      0.00        11\n",
      "          10       0.67      0.67      0.67         3\n",
      "          11       1.00      1.00      1.00         1\n",
      "          12       0.00      0.00      0.00         9\n",
      "          13       0.00      0.00      0.00         7\n",
      "          14       0.00      0.00      0.00         8\n",
      "          15       0.00      0.00      0.00         3\n",
      "          16       0.59      0.98      0.74       117\n",
      "\n",
      "    accuracy                           0.51       289\n",
      "   macro avg       0.20      0.19      0.18       289\n",
      "weighted avg       0.37      0.51      0.41       289\n",
      "\n",
      "\n",
      "==== Training XGBoost ====\n",
      "XGBoost Accuracy: 0.5294\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.00      0.00      0.00        13\n",
      "           2       0.43      0.20      0.27        15\n",
      "           3       0.00      0.00      0.00        14\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.36      0.54      0.43        61\n",
      "           6       0.00      0.00      0.00         9\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00        13\n",
      "           9       0.50      0.18      0.27        11\n",
      "          10       1.00      0.33      0.50         3\n",
      "          11       1.00      1.00      1.00         1\n",
      "          12       0.00      0.00      0.00         9\n",
      "          13       0.00      0.00      0.00         7\n",
      "          14       0.00      0.00      0.00         8\n",
      "          15       0.00      0.00      0.00         3\n",
      "          16       0.72      0.97      0.82       117\n",
      "\n",
      "    accuracy                           0.53       289\n",
      "   macro avg       0.24      0.19      0.19       289\n",
      "weighted avg       0.42      0.53      0.46       289\n",
      "\n",
      "\n",
      "==== Training SVM ====\n",
      "SVM Accuracy: 0.5190\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.00      0.00      0.00        13\n",
      "           2       1.00      0.20      0.33        15\n",
      "           3       0.00      0.00      0.00        14\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.46      0.49      0.48        61\n",
      "           6       0.50      0.22      0.31         9\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00        13\n",
      "           9       0.67      0.18      0.29        11\n",
      "          10       0.00      0.00      0.00         3\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00         9\n",
      "          13       0.00      0.00      0.00         7\n",
      "          14       0.00      0.00      0.00         8\n",
      "          15       0.00      0.00      0.00         3\n",
      "          16       0.55      0.97      0.70       117\n",
      "\n",
      "    accuracy                           0.52       289\n",
      "   macro avg       0.19      0.12      0.12       289\n",
      "weighted avg       0.41      0.52      0.42       289\n",
      "\n",
      "\n",
      "==== Training LSTM ====\n",
      "Epoch: 1\n",
      "\tTrain Loss: 2.0630, Train Acc: 0.4549\n",
      "\tVal Loss: 1.7865, Val Acc: 0.5172\n",
      "Epoch: 2\n",
      "\tTrain Loss: 1.7788, Train Acc: 0.5074\n",
      "\tVal Loss: 1.6995, Val Acc: 0.5241\n",
      "Epoch: 3\n",
      "\tTrain Loss: 1.7150, Train Acc: 0.5243\n",
      "\tVal Loss: 1.7178, Val Acc: 0.5172\n",
      "Epoch: 4\n",
      "\tTrain Loss: 1.6567, Train Acc: 0.5391\n",
      "\tVal Loss: 1.7572, Val Acc: 0.5034\n",
      "Epoch: 5\n",
      "\tTrain Loss: 1.5258, Train Acc: 0.5570\n",
      "\tVal Loss: 1.7163, Val Acc: 0.5241\n",
      "Epoch: 6\n",
      "\tTrain Loss: 1.6231, Train Acc: 0.5203\n",
      "\tVal Loss: 1.7256, Val Acc: 0.5241\n",
      "Epoch: 7\n",
      "\tTrain Loss: 1.4706, Train Acc: 0.5679\n",
      "\tVal Loss: 1.6980, Val Acc: 0.5103\n",
      "Epoch: 8\n",
      "\tTrain Loss: 1.3613, Train Acc: 0.5877\n",
      "\tVal Loss: 1.9878, Val Acc: 0.3586\n",
      "Epoch: 9\n",
      "\tTrain Loss: 1.2941, Train Acc: 0.5986\n",
      "\tVal Loss: 1.7565, Val Acc: 0.5103\n",
      "Epoch: 10\n",
      "\tTrain Loss: 1.2237, Train Acc: 0.6353\n",
      "\tVal Loss: 1.8999, Val Acc: 0.4138\n",
      "Test Loss: 1.9777, Test Acc: 0.5156\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.00      0.00      0.00        13\n",
      "           2       0.00      0.00      0.00        15\n",
      "           3       0.15      0.14      0.15        14\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.37      0.70      0.48        61\n",
      "           6       0.00      0.00      0.00         9\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00        13\n",
      "           9       0.00      0.00      0.00        11\n",
      "          10       0.75      1.00      0.86         3\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00         9\n",
      "          13       0.00      0.00      0.00         7\n",
      "          14       0.33      0.12      0.18         8\n",
      "          15       0.00      0.00      0.00         3\n",
      "          16       0.69      0.85      0.77       117\n",
      "\n",
      "    accuracy                           0.52       289\n",
      "   macro avg       0.14      0.17      0.14       289\n",
      "weighted avg       0.38      0.52      0.43       289\n",
      "\n",
      "\n",
      "==== Training GNN ====\n",
      "Converting texts to graphs...\n",
      "Epoch: 1\n",
      "\tTrain Loss: 2.2468, Train Acc: 0.3677\n",
      "\tVal Loss: 2.0479, Val Acc: 0.4069\n",
      "Epoch: 2\n",
      "\tTrain Loss: 2.0072, Train Acc: 0.4024\n",
      "\tVal Loss: 2.0252, Val Acc: 0.4069\n",
      "Epoch: 3\n",
      "\tTrain Loss: 1.9552, Train Acc: 0.4054\n",
      "\tVal Loss: 2.0160, Val Acc: 0.4069\n",
      "Epoch: 4\n",
      "\tTrain Loss: 1.8984, Train Acc: 0.4103\n",
      "\tVal Loss: 2.0098, Val Acc: 0.4138\n",
      "Epoch: 5\n",
      "\tTrain Loss: 1.8315, Train Acc: 0.4272\n",
      "\tVal Loss: 2.0446, Val Acc: 0.4069\n",
      "Epoch: 6\n",
      "\tTrain Loss: 1.7359, Train Acc: 0.4688\n",
      "\tVal Loss: 2.0618, Val Acc: 0.4207\n",
      "Epoch: 7\n",
      "\tTrain Loss: 1.5972, Train Acc: 0.5213\n",
      "\tVal Loss: 2.1626, Val Acc: 0.4345\n",
      "Epoch: 8\n",
      "\tTrain Loss: 1.4674, Train Acc: 0.5471\n",
      "\tVal Loss: 2.1918, Val Acc: 0.4345\n",
      "Epoch: 9\n",
      "\tTrain Loss: 1.3168, Train Acc: 0.5976\n",
      "\tVal Loss: 2.3107, Val Acc: 0.4690\n",
      "Epoch: 10\n",
      "\tTrain Loss: 1.1727, Train Acc: 0.6392\n",
      "\tVal Loss: 2.4215, Val Acc: 0.4138\n",
      "Test Loss: 2.1095, Test Acc: 0.4152\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.00      0.00      0.00        13\n",
      "           2       0.00      0.00      0.00        15\n",
      "           3       0.00      0.00      0.00        14\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.60      0.05      0.09        61\n",
      "           6       0.00      0.00      0.00         9\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00        13\n",
      "           9       0.00      0.00      0.00        11\n",
      "          10       0.00      0.00      0.00         3\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00         9\n",
      "          13       0.00      0.00      0.00         7\n",
      "          14       0.00      0.00      0.00         8\n",
      "          15       0.00      0.00      0.00         3\n",
      "          16       0.41      1.00      0.58       117\n",
      "\n",
      "    accuracy                           0.42       289\n",
      "   macro avg       0.06      0.06      0.04       289\n",
      "weighted avg       0.29      0.42      0.26       289\n",
      "\n",
      "\n",
      "==== Training BERT+LSTM ====\n",
      "Epoch: 1\n",
      "\tTrain Loss: 2.3858, Train Acc: 0.4163\n",
      "\tVal Loss: 1.8276, Val Acc: 0.5241\n",
      "Epoch: 2\n",
      "\tTrain Loss: 1.8318, Train Acc: 0.5332\n",
      "\tVal Loss: 1.5418, Val Acc: 0.5586\n",
      "Epoch: 3\n",
      "\tTrain Loss: 1.7246, Train Acc: 0.5560\n",
      "\tVal Loss: 1.5252, Val Acc: 0.5586\n",
      "Test Loss: 1.7904, Test Acc: 0.5606\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.00      0.00      0.00        13\n",
      "           2       0.00      0.00      0.00        15\n",
      "           3       0.00      0.00      0.00        14\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.34      0.87      0.49        61\n",
      "           6       0.00      0.00      0.00         9\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00        13\n",
      "           9       0.00      0.00      0.00        11\n",
      "          10       0.00      0.00      0.00         3\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00         9\n",
      "          13       0.00      0.00      0.00         7\n",
      "          14       0.00      0.00      0.00         8\n",
      "          15       0.00      0.00      0.00         3\n",
      "          16       0.81      0.93      0.87       117\n",
      "\n",
      "    accuracy                           0.56       289\n",
      "   macro avg       0.07      0.11      0.08       289\n",
      "weighted avg       0.40      0.56      0.45       289\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model: BERT+LSTM with accuracy: 0.5606\n",
      "Best model saved!\n"
     ]
    }
   ],
   "source": [
    "# Function to make predictions on new poems\n",
    "def predict_poem(poem_text, model_path='best_model.pkl'):\n",
    "    import joblib\n",
    "    \n",
    "    # Load model\n",
    "    if model_path.endswith('.pkl'):\n",
    "        model, vectorizer, label_encoder = joblib.load(model_path)\n",
    "        \n",
    "        # Preprocess text\n",
    "        processed_text = preprocess_text(poem_text)\n",
    "        \n",
    "        # Vectorize\n",
    "        X = vectorizer.transform([processed_text])\n",
    "        \n",
    "        # Predict\n",
    "        prediction = model.predict(X)[0]\n",
    "        predicted_class = label_encoder.inverse_transform([prediction])[0]\n",
    "        \n",
    "        return predicted_class\n",
    "    else:\n",
    "        print(\"Deep learning models require a different prediction approach.\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in c:\\users\\rahul\\anaconda3\\lib\\site-packages (0.20.3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'bert_lstm_architecture.png'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install graphviz\n",
    "\n",
    "from graphviz import Digraph\n",
    "\n",
    "# Create a Digraph object\n",
    "dot = Digraph(format='png')\n",
    "\n",
    "# Set overall styling\n",
    "dot.attr(rankdir='TB', bgcolor='white')\n",
    "\n",
    "# Add nodes for each stage\n",
    "dot.node('Input', 'Poetic Text\\n(Input)', shape='parallelogram', style='filled', fillcolor='lightblue', fontsize='14')\n",
    "\n",
    "dot.node('Tokenizer', 'BERT Tokenizer\\n(Tokenization)', shape='box', style='filled', fillcolor='lightgray', fontsize='14')\n",
    "\n",
    "dot.node('BERT', 'BERT Encoder\\n(Contextual Embeddings)', shape='box3d', style='filled', fillcolor='lightgoldenrodyellow', fontsize='14')\n",
    "\n",
    "dot.node('LSTM', 'Bidirectional LSTM\\n(Sequence Processing)', shape='box', style='filled', fillcolor='lightcoral', fontsize='14')\n",
    "\n",
    "dot.node('Dropout', 'Dropout Layer\\n(Regularization)', shape='ellipse', style='filled', fillcolor='lightsalmon', fontsize='14')\n",
    "\n",
    "dot.node('FC', 'Fully Connected Layer\\n(Dense Projection)', shape='box', style='filled', fillcolor='lightseagreen', fontsize='14')\n",
    "\n",
    "dot.node('Softmax', 'Softmax Layer\\n(Classification)', shape='ellipse', style='filled', fillcolor='orchid', fontsize='14')\n",
    "\n",
    "dot.node('Output', 'Sentiment/Theme/Form\\nPrediction', shape='parallelogram', style='filled', fillcolor='lightblue', fontsize='14')\n",
    "\n",
    "# Add edges to show data flow\n",
    "dot.edge('Input', 'Tokenizer', label='Tokenize')\n",
    "dot.edge('Tokenizer', 'BERT', label='Word Embeddings')\n",
    "dot.edge('BERT', 'LSTM', label='Contextual Features')\n",
    "dot.edge('LSTM', 'Dropout', label='Processed Sequence')\n",
    "dot.edge('Dropout', 'FC', label='Feature Projection')\n",
    "dot.edge('FC', 'Softmax', label='Class Probabilities')\n",
    "dot.edge('Softmax', 'Output', label='Final Classification')\n",
    "\n",
    "# Save and render the diagram\n",
    "dot.render('bert_lstm_architecture')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
